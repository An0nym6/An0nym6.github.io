<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.7.0">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2018-11-30T15:28:33-08:00</updated><id>/</id><title type="html">Random Thoughts</title><subtitle>©️ Designed by shuq3 &amp; An0nym6</subtitle><entry><title type="html">算法期末复习笔记</title><link href="/2018/11/29/%E7%AE%97%E6%B3%95%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0.html" rel="alternate" type="text/html" title="算法期末复习笔记" /><published>2018-11-29T20:00:00-08:00</published><updated>2018-11-29T20:00:00-08:00</updated><id>/2018/11/29/%E7%AE%97%E6%B3%95%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0</id><content type="html" xml:base="/2018/11/29/%E7%AE%97%E6%B3%95%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0.html">&lt;p&gt;这门课程所使用的教材是康奈尔的 Algorithm Design 和 MIT 的 Introduction to Algorithms，本份笔记直接沿用书本中对变量及名词的定义，在此没有对它们进行特殊解释。&lt;/p&gt;

&lt;h4 id=&quot;lecture-5&quot;&gt;Lecture 5&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;Steps for solving DP problems:
    &lt;ol&gt;
      &lt;li&gt;Describe subproblem;&lt;/li&gt;
      &lt;li&gt;Describe base case;&lt;/li&gt;
      &lt;li&gt;Describe recurrence;&lt;/li&gt;
      &lt;li&gt;Analyze complexity;&lt;/li&gt;
      &lt;li&gt;Write pseudo code.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;lecture-6&quot;&gt;Lecture 6&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;Shortest path:
    &lt;ul&gt;
      &lt;li&gt;Single source &amp;amp; positive-weighted: Dijkstra’s Algorithm;&lt;/li&gt;
      &lt;li&gt;Single source &amp;amp; negative-weighted: Bellman-Ford Algorithm;
        &lt;ul&gt;
          &lt;li&gt;Case 1: D[v, k] = D[v, k - 1], path uses at most k - 1 edges;&lt;/li&gt;
          &lt;li&gt;Case 2: D[v, k] = min&lt;sub&gt;(w, v)∈E&lt;/sub&gt;(D[w, k - 1] + C&lt;sub&gt;wv&lt;/sub&gt;);&lt;/li&gt;
          &lt;li&gt;Goal: Compute D(t, v - 1);&lt;/li&gt;
          &lt;li&gt;Complexity: O(EV);&lt;/li&gt;
          &lt;li&gt;Negative cycle? Run 1 more round for k = v, if D decrease for some point, then yes.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;All-pairs: 1. Run Bellman-Ford V times: O(EV&lt;sup&gt;2&lt;/sup&gt;); 2. Floyd-Warshall Algorithm;
        &lt;ul&gt;
          &lt;li&gt;D[i, j, k] = min&lt;sub&gt;u&lt;/sub&gt;(D[i, u, k - 1] + D[u, j, k - 1], D[i, j, k - 1]);&lt;/li&gt;
          &lt;li&gt;Pseudo code:
            &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  D[i,j,V[0]] = c[i,j] for all i and j
  for k in V:
    for i in V:
      for j in V:
        D[i,j,k] = min(D[i,k,k-1]+D[k,j,k-1],D[i,j,k-1])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;            &lt;/div&gt;
          &lt;/li&gt;
          &lt;li&gt;Complexity: O(V&lt;sup&gt;3&lt;/sup&gt;)&lt;/li&gt;
          &lt;li&gt;Negative cycle? If the diagonal has nagetive elements, then yes;&lt;/li&gt;
          &lt;li&gt;Extract the shortest path? Every time we update D[i, j], we set P[i, j] to k. Then we recursively compute the shortest path from i to k = P[i, j] and the path from k = P[i, j] to j.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;lecture-7&quot;&gt;Lecture 7&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;Max-flow problem: Ford-Fulkerson Algorithm:
    &lt;ul&gt;
      &lt;li&gt;Complexity: O(|f|(E + V));&lt;/li&gt;
      &lt;li&gt;Edmonds-Karp Algorithm: If we replace DFS with BFS, the complexity would be O(E&lt;sup&gt;2&lt;/sup&gt;V);&lt;/li&gt;
      &lt;li&gt;Capacity-Scaling Algorithm: If we choose the augmenting path with highest bottleneck capacity, the complexity would be O(log|f|E&lt;sup&gt;2&lt;/sup&gt;).&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Max-flow theorem: the following conditions are equivalent for any f:
    &lt;ul&gt;
      &lt;li&gt;∃ cut(A, B) s.t. cap(A, B) = |f|;&lt;/li&gt;
      &lt;li&gt;f is a max-flow;&lt;/li&gt;
      &lt;li&gt;There is no augmenting path wrt to f.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;Value of the max-flow = capacity of the min-cut.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Applications of max-flow:
    &lt;ul&gt;
      &lt;li&gt;Bipartite max matching: |f| ≤ V, V’ = 2V, so complexity: O(V(E + 2V)) = O(EV).&lt;/li&gt;
      &lt;li&gt;Maximum number of edge disjoint paths. Complexity: O(EV)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;lecture-8&quot;&gt;Lecture 8&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;Image segmentation problem: solved by min-cut problem.&lt;/li&gt;
  &lt;li&gt;Circulation problem can be reduced to max-flow problem: there is a feasible circulation in G if and only if the max-flow can achieve Σ&lt;sub&gt;d(v)&amp;gt;0&lt;/sub&gt;d(v).&lt;/li&gt;
  &lt;li&gt;Circulation problem with demands can be reduced to circulation problem without demands: just push the lower bounds of flow through each edges, then modify the capacity of each edge and demand of each vertex respectively.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Survey Design Problem.&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;lecture-9&quot;&gt;Lecture 9&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;Undecidable problems: there is no computer program that can always give the right answer: it may give the wrong answer, or run forever. NP-Hard contains undecidable problems.
    &lt;ul&gt;
      &lt;li&gt;Example: The halting problem.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;To prove X is in NP-Complete, we first prove X is in NP (answer can be verified in polynomial time), then we prove X is in NP-Hard (∃Y ∈ NP, Y ≤&lt;sub&gt;p&lt;/sub&gt; X).&lt;/li&gt;
  &lt;li&gt;NP-Complete problems are the most difficult NP problems.&lt;/li&gt;
  &lt;li&gt;Reductions of NP-Complete problems:
    &lt;ul&gt;
      &lt;li&gt;SAT is in NP-Complete without proof;&lt;/li&gt;
      &lt;li&gt;3-SAT ≤&lt;sub&gt;p&lt;/sub&gt; Independent set;&lt;/li&gt;
      &lt;li&gt;Independent set ≤&lt;sub&gt;p&lt;/sub&gt; Vertex cover;&lt;/li&gt;
      &lt;li&gt;Vertex cover ≤&lt;sub&gt;p&lt;/sub&gt; Vertex cover-even;&lt;/li&gt;
      &lt;li&gt;3-SAT ≤&lt;sub&gt;p&lt;/sub&gt; 3-colorable;&lt;/li&gt;
      &lt;li&gt;3-SAT ≤&lt;sub&gt;p&lt;/sub&gt; Hamiltonian Cycle (without proof).&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;lecture-10&quot;&gt;Lecture 10&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;Standard linear programming problem in matrix form:&lt;br /&gt;
 max(c&lt;sup&gt;T&lt;/sup&gt;x),&lt;br /&gt;
 subject to: Ax ≤ b, x ≥ 0.
    &lt;ul&gt;
      &lt;li&gt;Linear programming can be used to solve max-flow and shortest path problem.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Integer linear programming (ILP) is in NP-Hard.
    &lt;ul&gt;
      &lt;li&gt;Independent set ≤&lt;sub&gt;p&lt;/sub&gt; ILP;&lt;/li&gt;
      &lt;li&gt;ILP can be used to solve 0-1 Knapsack.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;The dual of standard linear programming problem:&lt;br /&gt;
 min(b&lt;sup&gt;T&lt;/sup&gt;y),&lt;br /&gt;
 subject to: A&lt;sup&gt;T&lt;/sup&gt;y ≥ c, y ≥ 0.
    &lt;ul&gt;
      &lt;li&gt;The weak duality: if x is a feasible solution for primal and y is a feasible solution for dual, then c&lt;sup&gt;T&lt;/sup&gt;x ≤ b&lt;sup&gt;T&lt;/sup&gt;y;&lt;/li&gt;
      &lt;li&gt;The strong duality: opt(primal) = opt(dual);&lt;/li&gt;
      &lt;li&gt;
        &lt;table&gt;
          &lt;thead&gt;
            &lt;tr&gt;
              &lt;th&gt;P \ D&lt;/th&gt;
              &lt;th&gt;F.B.&lt;/th&gt;
              &lt;th&gt;F.U.&lt;/th&gt;
              &lt;th&gt;I.&lt;/th&gt;
            &lt;/tr&gt;
          &lt;/thead&gt;
          &lt;tbody&gt;
            &lt;tr&gt;
              &lt;td&gt;F.B.&lt;/td&gt;
              &lt;td&gt;Yes&lt;/td&gt;
              &lt;td&gt;No&lt;/td&gt;
              &lt;td&gt;No&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
              &lt;td&gt;F.U.&lt;/td&gt;
              &lt;td&gt;No&lt;/td&gt;
              &lt;td&gt;No&lt;/td&gt;
              &lt;td&gt;Yes&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
              &lt;td&gt;I.&lt;/td&gt;
              &lt;td&gt;No&lt;/td&gt;
              &lt;td&gt;Yes&lt;/td&gt;
              &lt;td&gt;Yes&lt;/td&gt;
            &lt;/tr&gt;
          &lt;/tbody&gt;
        &lt;/table&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;General form of primal and dual:&lt;/p&gt;

    &lt;table&gt;
      &lt;thead&gt;
        &lt;tr&gt;
          &lt;th&gt;Primal&lt;/th&gt;
          &lt;th&gt;Dual&lt;/th&gt;
        &lt;/tr&gt;
      &lt;/thead&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;max(c&lt;sup&gt;T&lt;/sup&gt;x)&lt;/td&gt;
          &lt;td&gt;min(b&lt;sub&gt;1&lt;/sub&gt;&lt;sup&gt;T&lt;/sup&gt;y&lt;sub&gt;1&lt;/sub&gt; + b&lt;sub&gt;2&lt;/sub&gt;&lt;sup&gt;T&lt;/sup&gt;y&lt;sub&gt;2&lt;/sub&gt; + b&lt;sub&gt;3&lt;/sub&gt;&lt;sup&gt;T&lt;/sup&gt;y&lt;sub&gt;3&lt;/sub&gt;)&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
          &lt;td&gt;A&lt;sub&gt;1&lt;/sub&gt;x ≤ b&lt;sub&gt;1&lt;/sub&gt;&lt;/td&gt;
          &lt;td&gt;A&lt;sub&gt;1&lt;/sub&gt;&lt;sup&gt;T&lt;/sup&gt;y&lt;sub&gt;1&lt;/sub&gt; + A&lt;sub&gt;2&lt;/sub&gt;&lt;sup&gt;T&lt;/sup&gt;y&lt;sub&gt;2&lt;/sub&gt; + A&lt;sub&gt;3&lt;/sub&gt;&lt;sup&gt;T&lt;/sup&gt;y&lt;sub&gt;3&lt;/sub&gt; ≥ c&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
          &lt;td&gt;A&lt;sub&gt;2&lt;/sub&gt;x = b&lt;sub&gt;2&lt;/sub&gt;&lt;/td&gt;
          &lt;td&gt;y&lt;sub&gt;1&lt;/sub&gt; ≥ 0&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
          &lt;td&gt;A&lt;sub&gt;3&lt;/sub&gt;x ≥ b&lt;sub&gt;3&lt;/sub&gt;&lt;/td&gt;
          &lt;td&gt;y&lt;sub&gt;2&lt;/sub&gt; unrestricted&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
          &lt;td&gt;x ≥ 0&lt;/td&gt;
          &lt;td&gt;y&lt;sub&gt;3&lt;/sub&gt; ≤ 0&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;lecture-11&quot;&gt;Lecture 11&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;Classic approximation algorithms:
    &lt;ul&gt;
      &lt;li&gt;2-approximation vertex cover: find matchings in graph;&lt;/li&gt;
      &lt;li&gt;2-approximation TSP on complete graph with triangle inequality: use MST;&lt;/li&gt;
      &lt;li&gt;1.5-approximation TSP on complete graph with triangle inequality:
        &lt;ul&gt;
          &lt;li&gt;MST of G → T;&lt;/li&gt;
          &lt;li&gt;Vertices of odd degree in T → S;&lt;/li&gt;
          &lt;li&gt;Min-cost matching on S → M;&lt;/li&gt;
          &lt;li&gt;return T ∪ M.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;There is no polynomial α-approximation algorithm for general TSP: if such algorithm exists, we can use it to solve Hamiltonian Cycle.&lt;/li&gt;
      &lt;li&gt;ln n-approximation set cover: greedy, each move covers at least 1/k of the elements, so k * ln n moves will cover all (k is the optimal).&lt;/li&gt;
      &lt;li&gt;2-approximation load balance: greedy: assign next job to the machine with least load.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;lecture-12&quot;&gt;Lecture 12&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;Classification of random algorithm:
    &lt;ul&gt;
      &lt;li&gt;Las Vegas algorithms: always returns the correct answer, but may run longer than you expect.
        &lt;ul&gt;
          &lt;li&gt;Example: quick sort.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Monte Carlo algorithms: may fail or return incorrect answer, but the runtime is independent of input randomness.
        &lt;ul&gt;
          &lt;li&gt;Example: random global min-cut.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Random data structre:
    &lt;ul&gt;
      &lt;li&gt;Skip list: O(log n) search time;&lt;/li&gt;
      &lt;li&gt;Treap: a binary search tree with the heap ordering property (use rotation to maintain heap ordering property while do no change to BST ordering property).
        &lt;ul&gt;
          &lt;li&gt;Complexity: O(log n) search time &amp;amp; O(log n) insert time.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;</content><author><name></name></author><category term="学习笔记" /><summary type="html">这门课程所使用的教材是康奈尔的 Algorithm Design 和 MIT 的 Introduction to Algorithms，本份笔记直接沿用书本中对变量及名词的定义，在此没有对它们进行特殊解释。</summary></entry><entry><title type="html">AI 第三部分“机器学习”复习笔记</title><link href="/2018/11/24/AI-%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0.html" rel="alternate" type="text/html" title="AI 第三部分“机器学习”复习笔记" /><published>2018-11-24T20:00:00-08:00</published><updated>2018-11-24T20:00:00-08:00</updated><id>/2018/11/24/AI%20%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E2%80%9C%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%9D%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0</id><content type="html" xml:base="/2018/11/24/AI-%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0.html">&lt;p&gt;这门课程所使用的教材是 Artificial Intelligence: A Modern Approach，本份笔记直接沿用书本中对变量及名词的定义，在此没有对它们进行特殊解释。&lt;/p&gt;

&lt;h4 id=&quot;lecture-18-19&quot;&gt;Lecture 18-19&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;Bayes’ rule: P(A|B) = (P(B|A) · P(A)) / P(B).&lt;/li&gt;
  &lt;li&gt;Normalization &amp;amp; marginalization: P(X|e) = P(X, e) / P(e) = α · P(X, e) = α · Σ&lt;sub&gt;y&lt;/sub&gt; P(X, e, y).&lt;/li&gt;
  &lt;li&gt;In the alarm network, calls are conditionally independent of burglaries and earthquakes, but not independent of them.&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;lecture-20&quot;&gt;Lecture 20&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;Entropy: -Σ&lt;sub&gt;i&lt;/sub&gt; P(v&lt;sub&gt;i&lt;/sub&gt;) · ln(P(v&lt;sub&gt;i&lt;/sub&gt;)):
    &lt;ul&gt;
      &lt;li&gt;The more uniform the probability distribution, the greater its information.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;ID3 algorithm: Top-down construction of decision tree by recursively selecting “best attribute” to use at the current node in tree.
    &lt;ul&gt;
      &lt;li&gt;“best attribute”: Choose the attribute that has the largest expected information gain.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;lecture-20-21&quot;&gt;Lecture 20-21&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;Back-propagation is synchronous while Hopfield net is asynchronous; Back-propagation tries to minimize the error while Hopfield net tries to minimize the energy.&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;lecture-22&quot;&gt;Lecture 22&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;Markov Decision Process (MDP):
    &lt;ul&gt;
      &lt;li&gt;The problem is to find the optimal policy, which maximizes utility at each state;&lt;/li&gt;
      &lt;li&gt;Bellman equation: U(s) = R(s) + γ max&lt;sub&gt;a&lt;/sub&gt;(Σ&lt;sub&gt;s&lt;sub&gt;1&lt;/sub&gt;&lt;/sub&gt;(P(s&lt;sub&gt;1&lt;/sub&gt; | s, a) · U(s&lt;sub&gt;1&lt;/sub&gt;))). Repeating this formula will converge to optimal policy.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;lecture-23&quot;&gt;Lecture 23&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;Reinforcement Learning:
    &lt;ul&gt;
      &lt;li&gt;Utility-based agent: if it already knows the transition model, then use MDP algorithm to solve for Maximum Expectation Utility (MEU) actions.&lt;/li&gt;
      &lt;li&gt;Q-learning agent: if it doesn’t know the transition model, then pick action that has highest utility in current state.&lt;br /&gt;
        &lt;ul&gt;
          &lt;li&gt;Q(s, a) = Q(s, a) + α(R(s) + γ max&lt;sub&gt;a’&lt;/sub&gt; (Q(s’, a’) − Q(s, a))) →&lt;br /&gt;
  Q(s, a) = (1 - α)Q(s, a) + α(R(s) + γ max&lt;sub&gt;a’&lt;/sub&gt; Q(s’, a’))&lt;/li&gt;
          &lt;li&gt;Converge to correct values if α decays over time.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Reflex agent: learn a policy directly, then pick the action that the policy says.
        &lt;ul&gt;
          &lt;li&gt;Can start right away and then learn as it goes.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;lecture-24-25&quot;&gt;Lecture 24-25&lt;/h4&gt;

&lt;p&gt;Guest speaker.&lt;/p&gt;

&lt;h4 id=&quot;lecture-26&quot;&gt;Lecture 26&lt;/h4&gt;

&lt;p&gt;🍺&lt;/p&gt;</content><author><name></name></author><category term="学习笔记" /><summary type="html">这门课程所使用的教材是 Artificial Intelligence: A Modern Approach，本份笔记直接沿用书本中对变量及名词的定义，在此没有对它们进行特殊解释。</summary></entry><entry><title type="html">AI 第二部分“逻辑”复习笔记</title><link href="/2018/10/26/AI-%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86-%E9%80%BB%E8%BE%91-%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0.html" rel="alternate" type="text/html" title="AI 第二部分“逻辑”复习笔记" /><published>2018-10-26T21:00:00-07:00</published><updated>2018-10-26T21:00:00-07:00</updated><id>/2018/10/26/AI%20%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86%E2%80%9C%E9%80%BB%E8%BE%91%E2%80%9D%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0</id><content type="html" xml:base="/2018/10/26/AI-%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86-%E9%80%BB%E8%BE%91-%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0.html">&lt;p&gt;这门课程所使用的教材是 Artificial Intelligence: A Modern Approach，本份笔记直接沿用书本中对变量及名词的定义，在此没有对它们进行特殊解释。&lt;/p&gt;

&lt;h4 id=&quot;lecture-9-10&quot;&gt;Lecture 9-10&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;Syntax (语法): how sentences are expressed; semantics (语义): meaning of the sentence, e.g., truth value.&lt;/li&gt;
  &lt;li&gt;If a sentence α is true in model m, we say m satisfies α, or m is a model of α:
    &lt;ul&gt;
      &lt;li&gt;M(α) is the set of all models of α; M(KB) is the set of all models of KB;&lt;/li&gt;
      &lt;li&gt;KB ⊨ α if and only if M(KB) is a subset M(α).&lt;/li&gt;
      &lt;li&gt;KB ⊨ α: KB entails sentence α, if and only if, α is true in all worlds where KB is true.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Entailment (⊨) is different from inference (⊢). Think of inference a the process of finding the entailment:
    &lt;ul&gt;
      &lt;li&gt;KB ⊢i α = sentence α can be derived from KB by procedure i.&lt;/li&gt;
      &lt;li&gt;Soundness: i is sound if whenever KB ⊢i α, it is also true that KB ⊨ α.&lt;/li&gt;
      &lt;li&gt;Completeness: i is complete if whenever KB ⊨ α, it is also true that KB ⊢i α.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Proof methods:
    &lt;ol&gt;
      &lt;li&gt;Model checking: Truth table enumeration (sound and complete); Heuristic search in model space (sound but incomplete);&lt;/li&gt;
      &lt;li&gt;Application of inference rules.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;A sentence is valid if it is true in all models (tautologies); A sentence is satisfiable if it is true in at least one model.
    &lt;ul&gt;
      &lt;li&gt;α is valid if and only if ¬α is unsatisfiable;&lt;/li&gt;
      &lt;li&gt;α is satisfiable if and only if ¬α is not valid.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Names for important tautologies:
    &lt;ul&gt;
      &lt;li&gt;Commutativity of ⋀ / ⋁: 交换律&lt;/li&gt;
      &lt;li&gt;Associativity of ⋀ / ⋁: 结合律&lt;/li&gt;
      &lt;li&gt;Double-negation elimination&lt;/li&gt;
      &lt;li&gt;Contraposition: α ⇒ β ⇔ ¬β ⇒ ¬α&lt;/li&gt;
      &lt;li&gt;Implication elimination&lt;/li&gt;
      &lt;li&gt;Biconditional elimination&lt;/li&gt;
      &lt;li&gt;De Morgan&lt;/li&gt;
      &lt;li&gt;Distributivity of ⋀ / ⋁ over ⋁ / ⋀: 分配律&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;α ⊨ β if and only if the sentence (α ⋀ ¬β) is unsatisfiable.&lt;/li&gt;
  &lt;li&gt;Names for inference rules:
    &lt;ul&gt;
      &lt;li&gt;Modus ponens: from α ⇒ β, α, we get β&lt;/li&gt;
      &lt;li&gt;Modus tollens: from α ⇒ β, ¬β, we get ¬α&lt;/li&gt;
      &lt;li&gt;And-elimination: from α ⋀ β, we get α&lt;/li&gt;
      &lt;li&gt;Or-introduction: from α, we get α ⋁ β&lt;/li&gt;
      &lt;li&gt;Both directions of all tautologies like contraposition: (α ⇒ β) ⇔ (¬β ⇒ ¬α)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;lecture-11-12&quot;&gt;Lecture 11-12&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;Resolution Inference: Complete when coupled with complete search algorithm.
    &lt;ul&gt;
      &lt;li&gt;To prove that KB ⊨ α, we show that (KB ⋀ ¬α) is unsatisfiable:
        &lt;ol&gt;
          &lt;li&gt;Convert (KB ⋀ ¬α) to CNF;&lt;/li&gt;
          &lt;li&gt;Apply the resolution rule wherever possible and add the result as an additional clause in the conjunction;&lt;/li&gt;
          &lt;li&gt;Repeat step 2 until either:
            &lt;ul&gt;
              &lt;li&gt;No new clauses can be added: KB does not entail α.&lt;/li&gt;
              &lt;li&gt;Two clauses resolve to yield the empty clause: KB entails α.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;If each clause is a horn clause in KB and the queries are atomic, then we can use linear-time algorithm forward chaining and backward chaining to do the inference. Complexity for backward chaining can be much less than linear in size of KB.&lt;/li&gt;
  &lt;li&gt;Symbols for constants, predicates and functions usually start with upper-case letters; Variables are written in lowercase letters.&lt;/li&gt;
  &lt;li&gt;⇒ is a natural connective to use with ∀; ⋀ is a natural connective to use with ∃.&lt;/li&gt;
  &lt;li&gt;De Morgan for quantifier negation: ¬∀x P ⇔ ∃x ¬P.&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;lecture-13&quot;&gt;Lecture 13&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;A ground literal’s terms are all ground terms; A ground term is a term without variables.&lt;/li&gt;
  &lt;li&gt;SUBST(θ, α): rewrite a sentence, α, by applying substitution, θ.&lt;/li&gt;
  &lt;li&gt;For every unifiable pair of expressions there is a Most General Unifier (a unique substitution) that equates the pair while making the fewest restrictions on the values of the variables.&lt;/li&gt;
  &lt;li&gt;First-order definite clauses are disjunctions of literals, of which exactly one is positive:
    &lt;ul&gt;
      &lt;li&gt;Atomic sentences (positive literals) are also definite clauses;&lt;/li&gt;
      &lt;li&gt;Definite clauses can include variables. The variables are assumed to be universally quantified.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Datalog Knowledge base contains only first-order definite clauses with no function symbols.&lt;/li&gt;
  &lt;li&gt;Forward chaining is sound and complete for first-order definete clauses. We can use CSP heuristics like Minimum-Remaining Value to imporve efficiency. We can also do incremental forward chaining – only consider rules with premise that involves a literal that can unify with the facts newly inferred from the previous iteration.&lt;/li&gt;
  &lt;li&gt;Backward chaining is sound but incomplete due to infinite loops. But it’s linear in size of proof.&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;lecture-14&quot;&gt;Lecture 14&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;Herbrand’s theorem: If there is a proof that a sentence is entailed by the original first-order knowledge base, then there is a proof involving just a finite subset of the propositionalized knowledge base. Entailment for first-order logic is semidecidable. We can say yes to every entailed sentence, but there is no way to say no to every non-entailed sentence.&lt;/li&gt;
  &lt;li&gt;CNF conversion for first-order logic:
    &lt;ol&gt;
      &lt;li&gt;Eliminate implications;&lt;/li&gt;
      &lt;li&gt;Move ¬ inward;&lt;/li&gt;
      &lt;li&gt;Standardize variables;&lt;/li&gt;
      &lt;li&gt;Skolemization;
        &lt;ul&gt;
          &lt;li&gt;Unique function names;&lt;/li&gt;
          &lt;li&gt;Arguments for all of the universally quantified variables in whose scope the existential quantifier appears;&lt;/li&gt;
          &lt;li&gt;We used Skolem Constants to remove existential quantifiers when the sentence was in a specific form (存在量词在最外面);&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Drop universal quantifiers;&lt;/li&gt;
      &lt;li&gt;Distribute ⋁ over ⋀.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;Russell’s Paradox:
    &lt;ul&gt;
      &lt;li&gt;The paradox arises within naive set theory by considering the set of all sets that are not members of themselves.&lt;/li&gt;
      &lt;li&gt;A master catalog of all library catalogs which do not include themselves.&lt;/li&gt;
      &lt;li&gt;A barber who shaves exactly those people who do not shave themselves.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Prolog.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;(不知道为什么没有 Lecture 15)&lt;/p&gt;

&lt;h4 id=&quot;lecture-16&quot;&gt;Lecture 16&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;Knowledge engineering is declarative (not procedural).&lt;/li&gt;
  &lt;li&gt;Propositional and first-order logic are monotonic:
    &lt;ul&gt;
      &lt;li&gt;As new sentences α are added to KB what is entailed can never decrease.&lt;/li&gt;
      &lt;li&gt;Non-monotonic logic eliminates this restriction.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;4 efforts of knowledge sharing:
    &lt;ul&gt;
      &lt;li&gt;Knowledge Interchange Format (KIF): Translate from KB1 to KIF then to KB2;&lt;/li&gt;
      &lt;li&gt;Knowledge Representation System Specification: Create “standard” specification for KR language within a particular family of languages;&lt;/li&gt;
      &lt;li&gt;Standardized Query Interface: Share across KBs by querying from one KB to the other (as in databases);&lt;/li&gt;
      &lt;li&gt;Shared, Reusable Knowledge Bases: Create a common “upper” ontology that can form the basis for many knowledge based systems.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;4 possible KRR (knowledge representation and reasoning) approaches:
    &lt;ul&gt;
      &lt;li&gt;Knowledge engineering: Write down all of the necessary knowledge in a manner that supports automated inference;
        &lt;ul&gt;
          &lt;li&gt;Cyc / OpenMind Common Sense&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Semantic web: Distribute the knowledge engineering task across the entire world, supported by international standards for encoding knowledge;
        &lt;ul&gt;
          &lt;li&gt;WikiData&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Knowledge extraction: Find knowledge in natural language text (e.g. social media), and convert it into a representation that supports automated reasoning;
        &lt;ul&gt;
          &lt;li&gt;Hearst Patterns / Commonsense axioms from text&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Experiential learning: Build a robot that can learn the knowledge by interacting with the world, just like a human child does;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;lecture-17&quot;&gt;Lecture 17&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;Situation Calculus:
    &lt;ul&gt;
      &lt;li&gt;Situations: Each time step is a “situation”. A function Result(a, s) gives the situation resulting from applying action a in situation s;&lt;/li&gt;
      &lt;li&gt;Fluents: Functions &amp;amp; predicates whose truth values can change from one situation to the other;&lt;/li&gt;
      &lt;li&gt;Atemporal (or eternal) predicates and functions.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Classical issues:
    &lt;ul&gt;
      &lt;li&gt;Frame problem: Representing all things that stay the same from one situation to the next;&lt;/li&gt;
      &lt;li&gt;Qualification problem: Defining the circumstances under which an action is guaranteed to work;&lt;/li&gt;
      &lt;li&gt;Ramification problem: Proliferation of implicit consequences of actions as actions may have secondary consequences.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;STRIPS-style planning:
    &lt;ul&gt;
      &lt;li&gt;Representing states:
        &lt;ul&gt;
          &lt;li&gt;A conjunction of positive literals (must be grounded and function free);&lt;/li&gt;
          &lt;li&gt;Closed world assumption: If not explicitly mentioned as true, assumed false.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Representing goals:
        &lt;ul&gt;
          &lt;li&gt;Generally a partial state specification (still must be positive, grounded and function free);&lt;/li&gt;
          &lt;li&gt;A goal is satisfied if state contains all literals in goal.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Representing actions:
        &lt;ul&gt;
          &lt;li&gt;An action is specified by a name, a list of parameters, a precondition and an effect:
            &lt;ul&gt;
              &lt;li&gt;PRECOND: Must be true in state for action to execute (conjunction of function-free positive literals);&lt;/li&gt;
              &lt;li&gt;EFFECT: Changes to state when action executes (conjunction of function-free literals); Positive literals add facts, negated literals remove facts.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Assumption: Every literal not modified by EFFECT remains unchanged to avoids representational frame problem.&lt;/li&gt;
      &lt;li&gt;Planning Domain Definition Language (PDDL) is slightly more expressive (allows negative literals in goals and preconditions):
        &lt;ul&gt;
          &lt;li&gt;Neither language allows functions;&lt;/li&gt;
          &lt;li&gt;Neither deals with the ramification problem;&lt;/li&gt;
          &lt;li&gt;Neither deals with the qualification problem.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Forward: Progression planner / Backward: Regression planner. Both progression and regression are still NP-hard.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Partial-order planning (POP):
    &lt;ul&gt;
      &lt;li&gt;Each plan has 4 components:
        &lt;ul&gt;
          &lt;li&gt;A set of actions (steps in the plan);&lt;/li&gt;
          &lt;li&gt;A set of ordering constraints: A &amp;lt; B (A before B);&lt;/li&gt;
          &lt;li&gt;A set of causal links (protection intervals);&lt;/li&gt;
          &lt;li&gt;A set of open preconditions (goals).&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Planning graph:
    &lt;ul&gt;
      &lt;li&gt;A planning graph consists of a sequence of levels that correspond to steps in the plan; each level consists of a set of literals and a set of actions:
        &lt;ul&gt;
          &lt;li&gt;Literals = all those that could be true at that time step, based on the actions executed at preceding time steps;&lt;/li&gt;
          &lt;li&gt;Actions = all those actions that could have their preconditions satisfied at that time step, based on which literals actually hold;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Connect preconditions of actions in A0 to S0 and effects to S1; Inaction is represented by persistence actions (like frame axioms);&lt;/li&gt;
      &lt;li&gt;Conflicts:
        &lt;ul&gt;
          &lt;li&gt;A mutex relation holds between two actions when:
            &lt;ul&gt;
              &lt;li&gt;Inconsistent effects: one action negates the effect of another;&lt;/li&gt;
              &lt;li&gt;Interference: an effect of one action negates a precondition of the other;&lt;/li&gt;
              &lt;li&gt;Competing needs: a precondition of one action is mutually exclusive with a precondition of the other;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;A mutex relation holds between two literals when:
            &lt;ul&gt;
              &lt;li&gt;One is the negation of the other;&lt;/li&gt;
              &lt;li&gt;Each possible action pair that could achieve the literals is mutex;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Stop when two consecutive levels are identical; complexity is polynomial.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;</content><author><name></name></author><category term="学习笔记" /><summary type="html">这门课程所使用的教材是 Artificial Intelligence: A Modern Approach，本份笔记直接沿用书本中对变量及名词的定义，在此没有对它们进行特殊解释。</summary></entry><entry><title type="html">算法期中复习笔记</title><link href="/2018/10/09/%E7%AE%97%E6%B3%95%E6%9C%9F%E4%B8%AD%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0.html" rel="alternate" type="text/html" title="算法期中复习笔记" /><published>2018-10-09T21:00:00-07:00</published><updated>2018-10-09T21:00:00-07:00</updated><id>/2018/10/09/%E7%AE%97%E6%B3%95%E6%9C%9F%E4%B8%AD%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0</id><content type="html" xml:base="/2018/10/09/%E7%AE%97%E6%B3%95%E6%9C%9F%E4%B8%AD%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0.html">&lt;p&gt;这门课程所使用的教材是康奈尔的 Algorithm Design 和 MIT 的 Introduction to Algorithms，本份笔记直接沿用书本中对变量及名词的定义，在此没有对它们进行特殊解释。&lt;/p&gt;

&lt;h4 id=&quot;lecture-1&quot;&gt;Lecture 1&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;we say f(n) = O(g(n)) if g(n) eventually dominates f(n). Formally: there exists a constant c such that for all sufficiently large n: f(n) ≤ c * g(n). The definition for Ω is similar to the definition for O. If f(n) = O(g(n)) and f(n) = Ω(g(n)), then f(n) = Θ(g(n)).
    &lt;ul&gt;
      &lt;li&gt;(1/3)^n + 100 = O(1) is True.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;The handshaking theorem: 2 * E = Σx∈V deg(x) (undirected graph)&lt;/li&gt;
  &lt;li&gt;Adjacency List Representation is used for representation of the sparse (E = O(V)) graphs; Adjacency Matrix Representation is used for representation of the dense (E = Ω(V^2)) graphs.
    &lt;ul&gt;
      &lt;li&gt;Maximally sparse connected graph: tree;&lt;/li&gt;
      &lt;li&gt;Maximally dense connected graph: complete graph Kn.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Linear time topological sort for DAG algorithm:
    &lt;ul&gt;
      &lt;li&gt;Select a vertex;&lt;/li&gt;
      &lt;li&gt;Run DFS and return vertices that has no undiscovered leaving edges;&lt;/li&gt;
      &lt;li&gt;May run DFS several times.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Is strongly connected graphs:
    &lt;ul&gt;
      &lt;li&gt;Select a vertex;&lt;/li&gt;
      &lt;li&gt;Run DFS, if some vertices are not reachable, stop;&lt;/li&gt;
      &lt;li&gt;Construct GT and run DFS again, if some vertices are not reachable, stop.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Euler’s Formula: If G is a connected planar graph, then V – E + F = 2 (proof is by induction).&lt;/li&gt;
  &lt;li&gt;4 Color Theorem: Any simple planar graph can be colored with less than or equal to 4 colors.&lt;/li&gt;
  &lt;li&gt;A graph is bipartite if the vertices can be partitioned into two disjoint sets. A subset of edges is a matching if no two edges have a common vertex.&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;lecture-2&quot;&gt;Lecture 2&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;Complete Binary Tree: completely filled, except the bottom level that is filled from left to right; and a binary heap is a complete binary tree which satisfies the heap ordering property.&lt;/li&gt;
  &lt;li&gt;In heap, consider the k-th element of the array:
    &lt;ul&gt;
      &lt;li&gt;Its left child is located at 2 * k index;&lt;/li&gt;
      &lt;li&gt;Its right child is located at 2 * k + 1 index;&lt;/li&gt;
      &lt;li&gt;Its parent is located at k / 2 index.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Heap operations:
    &lt;ul&gt;
      &lt;li&gt;Insert: insert at the end, then percolate it up by swapping positions with the parent, if it’s necessary;&lt;/li&gt;
      &lt;li&gt;deleteMin: move the last element of the heap to the root and then restore the heap property by percolating down; So the complexity for heap sort is O(n * log n)&lt;/li&gt;
      &lt;li&gt;decreaseKey: restore a heap property by percolating up this item;&lt;/li&gt;
      &lt;li&gt;buildHeap: by insertion: O(n * log n); heapify: O(n).&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Binomial heap operations:
    &lt;ul&gt;
      &lt;li&gt;merge: make the larger root to be the child of the smaller root. Complexity: O(log n);&lt;/li&gt;
      &lt;li&gt;deleteMin: find the binomial tree that contains the min; delete the root and move subtrees to top list; then merge the binomial trees. Complexity: O(log n);&lt;/li&gt;
      &lt;li&gt;insert: merge trees.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Amortized analysis gives the average performance (over time) of each operation in the worst case.
    &lt;ul&gt;
      &lt;li&gt;The amortized cost of insertion of Binomial heap is constant O(2).&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Complexities:&lt;/li&gt;
&lt;/ol&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt;Binary&lt;/th&gt;
      &lt;th&gt;Binomial&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;findMin&lt;/td&gt;
      &lt;td&gt;Θ(1)&lt;/td&gt;
      &lt;td&gt;Θ(1)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;deleteMin&lt;/td&gt;
      &lt;td&gt;Θ(log n)&lt;/td&gt;
      &lt;td&gt;Θ(log n)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;insert&lt;/td&gt;
      &lt;td&gt;Θ(log n)&lt;/td&gt;
      &lt;td&gt;Θ(1) (amortized complexity)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;decreaseKey&lt;/td&gt;
      &lt;td&gt;Θ(log n)&lt;/td&gt;
      &lt;td&gt;Θ(log n)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;merge&lt;/td&gt;
      &lt;td&gt;Θ(n)&lt;/td&gt;
      &lt;td&gt;Θ(log n)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&quot;lecture-3&quot;&gt;Lecture 3&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;Scheduling Problem: early finish time first. Complexity: O(n * log n).&lt;/li&gt;
  &lt;li&gt;Minimum Spanning Tree:
    &lt;ul&gt;
      &lt;li&gt;Kruskal’s Algorithm: Continue choosing the minimum weight edge that will not create a cycle until all vertices are connected.
        &lt;ul&gt;
          &lt;li&gt;Sorting edges: O(E * log E);&lt;/li&gt;
          &lt;li&gt;Cycle detection: O(V);&lt;/li&gt;
          &lt;li&gt;Total: O(E * log E + E * V).&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Prim’s Algorithm: Start with an arbitrary vertex as a sub-tree C; Expand C by adding a vertex having the minimum weight edge of the graph having exactly one end point in C; Update distances from C to adjacent vertices; Continue doing this until all vertices are connected.
        &lt;ul&gt;
          &lt;li&gt;If we use an array to maintain vertices distance to C, then findMin / deleteMin needs O(V), and update needs O(1). Complexity: O(V ^ 2 + E);&lt;/li&gt;
          &lt;li&gt;If we use a heap, then findMin / deleteMin needs O(log V), and update needs O(log V). Complexity: O(V * log V + E * log V);&lt;/li&gt;
          &lt;li&gt;If graph is dense -&amp;gt; array; if graph is sparse -&amp;gt; heap.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;If a connected undirected graph G = (V, E) has V + 10000 edges, we can find an MST of G in O(V) runtime.
        &lt;ul&gt;
          &lt;li&gt;True. Randomly generate a spanning tree (O(n)), for each edge in the last 10000 edges, add it to the tree, delete the max edge in the cycle (O(n)). So the total complexity should be 10000 * O(n) = O(n).&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;The Shortest Path Problem:
    &lt;ul&gt;
      &lt;li&gt;Dijkstra’s Algorithm: almost identical to Prim’s algorithm, but picks the shortest path from the source. It’s complexity is same as Prim’s Algorithm.
        &lt;ul&gt;
          &lt;li&gt;If priority queue is an array: O(V ^ 2 + E);&lt;/li&gt;
          &lt;li&gt;If priority queue is a heap: O(V * log V + E * log V);&lt;/li&gt;
          &lt;li&gt;If graph is dense (E = V ^ 2) -&amp;gt; array O(V ^ 2); if graph is sparse -&amp;gt; heap O(V * log V)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;lecture-4&quot;&gt;Lecture 4&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;The Master Theorem: T(n) = a * T(n / b) + f(n), where a ≥ 1 and b &amp;gt; 1 are constants and f(n) is a positive function, c = logb(a):
    &lt;ul&gt;
      &lt;li&gt;Case 1: if f(n) = O(n^(c-ε)), then T(n) = Θ(n ^ c); (only leaves)&lt;/li&gt;
      &lt;li&gt;Case 2: if f(n) = Θ(n^c * (log n) ^ k), k ≥ 0, then T(n) = Θ(n^c * (log n)^(k + 1)); (all nodes)&lt;/li&gt;
      &lt;li&gt;Case 3: if f(n) = Ω(n^(c+ε)), then T(n) = Θ(f(n)); (only internal nodes)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Closest pair of points: T(n) = 2 * T(n / 2) + O(n * log n), so the complexity should be Θ(n * (log n) ^ 2)&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;lecture-5&quot;&gt;Lecture 5&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;Two Approaches for DP:
    &lt;ul&gt;
      &lt;li&gt;Memoization: a top-down approach;&lt;/li&gt;
      &lt;li&gt;Tabulation: a bottom-up approach.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Pseudo-Polynomial Algorithm: A numeric algorithm runs in pseudo-polynomial time if its running time is polynomial in the numeric value of the input, but is exponential in the length of the input: T(n) = Θ(n·W).&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;lecture-6&quot;&gt;Lecture 6&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;Basic steps for DP:
    &lt;ul&gt;
      &lt;li&gt;Define subproblems;&lt;/li&gt;
      &lt;li&gt;Write the recurrence relation;&lt;/li&gt;
      &lt;li&gt;Construct the solution in bottom-up way;&lt;/li&gt;
      &lt;li&gt;Compute its runtime complexity.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Bellman-Ford Algorithm:
    &lt;ul&gt;
      &lt;li&gt;How would you apply the Bellman-Ford algorithm to find out if a graph has a negative cycle? Run 1 more round for k = V, if the distance reduced for some point, there must be a negative cycle.&lt;/li&gt;
      &lt;li&gt;Complexity: O(E * V).&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;D[v, 0] = INFINITY for all v != s
D[s, k] = 0 for all k
for k = 1 to V-1 do
  for each v in V do
    for each neighbor w of v do
      D[v, k] = min(D[v, k - 1], c(w, v) + D[w, k - 1])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ol&gt;
  &lt;li&gt;Floyd-Warshall Algorithm:
    &lt;ul&gt;
      &lt;li&gt;If the diagonal has negative numbers, then there must be a negative cycle.&lt;/li&gt;
      &lt;li&gt;How do we extract the shortest path? Every time we update D[i, j], we set P[i, j] to k. Then we recursively compute the shortest path from from i to k = P[i, j] and the path from from k = P[i, j] to j.&lt;/li&gt;
      &lt;li&gt;Complexity: O(V ^ 3)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;D[i, j, 0] = c[i, j] for all i and j
for k = 1 ... V do
  for i = 1 ... V do
    for j = 1 ... V do
      D[i, j, k] = min (D[i, j, k - 1], D[i, k, k - 1] + D[k, j, k - 1])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name></name></author><category term="学习笔记" /><summary type="html">这门课程所使用的教材是康奈尔的 Algorithm Design 和 MIT 的 Introduction to Algorithms，本份笔记直接沿用书本中对变量及名词的定义，在此没有对它们进行特殊解释。</summary></entry><entry><title type="html">AI 第一部分“搜索”复习笔记</title><link href="/2018/09/22/AI-%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86-%E6%90%9C%E7%B4%A2-%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0.html" rel="alternate" type="text/html" title="AI 第一部分“搜索”复习笔记" /><published>2018-09-22T21:00:00-07:00</published><updated>2018-09-22T21:00:00-07:00</updated><id>/2018/09/22/AI%20%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E2%80%9C%E6%90%9C%E7%B4%A2%E2%80%9D%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0</id><content type="html" xml:base="/2018/09/22/AI-%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86-%E6%90%9C%E7%B4%A2-%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0.html">&lt;p&gt;这门课程所使用的教材是 Artificial Intelligence: A Modern Approach，本份笔记直接沿用书本中对变量及名词的定义，在此没有对它们进行特殊解释。&lt;/p&gt;

&lt;h4 id=&quot;lecture-1&quot;&gt;Lecture 1&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;Agents are systems that perceive and act in some environment, including humans, robots, softbots, thermostats, etc.&lt;/li&gt;
  &lt;li&gt;Environment is world in which agent operates.&lt;/li&gt;
  &lt;li&gt;Cognitive Cycle: Perception, Memory Access, Decision, Learning, Action.&lt;/li&gt;
  &lt;li&gt;The agent function is a mathematical relationship that maps percept sequences to actions in the environment.&lt;/li&gt;
  &lt;li&gt;The agent function is computed by an agent program; the agent program runs on the physical architecture to implement the function.&lt;/li&gt;
  &lt;li&gt;A rational agent chooses whichever action maximizes the expected value of the performance measure given the percept sequence to date and the prior environment knowledge.&lt;/li&gt;
  &lt;li&gt;PEAS description of the task environment:
    &lt;ul&gt;
      &lt;li&gt;Performance: Measure for success/progress/quality;&lt;/li&gt;
      &lt;li&gt;Environment: The world in which the agent operates;&lt;/li&gt;
      &lt;li&gt;Actuators: How the agent affects the environment;&lt;/li&gt;
      &lt;li&gt;Sensors: How the agent perceives the environment.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Environment Types: fully vs. partially observable; deterministic vs. stochastic; episodic vs. sequential; static vs. dynamic; discrete vs. continuous; single vs. multi-agent.&lt;/li&gt;
  &lt;li&gt;Four basic kinds of agent programs:
    &lt;ul&gt;
      &lt;li&gt;Simple reflex agents: Select action on the basis of only the current percept;&lt;/li&gt;
      &lt;li&gt;Model-based reflex agents: To tackle partially observable environments; maintain internal state representing best estimate of current world situation; over time update state using world knowledge;&lt;/li&gt;
      &lt;li&gt;Goal-based agents: Goals describe what agent wants; by changing goals, can change what agent does in same situation;&lt;/li&gt;
      &lt;li&gt;Utility-based agents: Some solutions may be “better” – have higher utility; utility function maps a (sequence of) state(s) onto a real number which can help in optimization or in arbitration among goals or solutions;&lt;/li&gt;
      &lt;li&gt;All can be turned into learning agents; And a more complex variation is Hybrid agents.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;lecture-2-4&quot;&gt;Lecture 2-4&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;Blind/uninformed search; heuristic/informed search&lt;/li&gt;
  &lt;li&gt;Uninformed search stratigies:&lt;/li&gt;
&lt;/ol&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt;BFS&lt;/th&gt;
      &lt;th&gt;Uniform Cost&lt;/th&gt;
      &lt;th&gt;DFS&lt;/th&gt;
      &lt;th&gt;Depth limited&lt;/th&gt;
      &lt;th&gt;Iterative deepening&lt;/th&gt;
      &lt;th&gt;Bidirectional&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Complete?&lt;/td&gt;
      &lt;td&gt;Y&lt;/td&gt;
      &lt;td&gt;Y&lt;/td&gt;
      &lt;td&gt;N&lt;/td&gt;
      &lt;td&gt;N&lt;/td&gt;
      &lt;td&gt;Y&lt;/td&gt;
      &lt;td&gt;Y&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Optimal?&lt;/td&gt;
      &lt;td&gt;Y&lt;/td&gt;
      &lt;td&gt;Y&lt;/td&gt;
      &lt;td&gt;N&lt;/td&gt;
      &lt;td&gt;N&lt;/td&gt;
      &lt;td&gt;Y&lt;/td&gt;
      &lt;td&gt;Y&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Time&lt;/td&gt;
      &lt;td&gt;b^d&lt;/td&gt;
      &lt;td&gt;b^(1 + C* / ε)&lt;/td&gt;
      &lt;td&gt;b^m&lt;/td&gt;
      &lt;td&gt;b^l&lt;/td&gt;
      &lt;td&gt;b^d&lt;/td&gt;
      &lt;td&gt;b^(d / 2)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Space&lt;/td&gt;
      &lt;td&gt;b^d&lt;/td&gt;
      &lt;td&gt;b^(1 + C* / ε)&lt;/td&gt;
      &lt;td&gt;b * m&lt;/td&gt;
      &lt;td&gt;b * l&lt;/td&gt;
      &lt;td&gt;b * d&lt;/td&gt;
      &lt;td&gt;b^(d / 2)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;ol&gt;
  &lt;li&gt;Why do people have a hard time solving missionaries and cannibals? There are a number of constraints on solutions to this problem, for example, the boat only holds one or two people, you can never have more cannibals than missionaries on either side of the river, etc. Constraints are generally thought of as making it harder to solve a problem.&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;lecture-5&quot;&gt;Lecture 5&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;Informed search stratigies:&lt;/li&gt;
&lt;/ol&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt;BestFS&lt;/th&gt;
      &lt;th&gt;A*&lt;/th&gt;
      &lt;th&gt;RBFS&lt;/th&gt;
      &lt;th&gt;((S)MA*)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Complete?&lt;/td&gt;
      &lt;td&gt;N&lt;/td&gt;
      &lt;td&gt;Y&lt;/td&gt;
      &lt;td&gt;Y (same as A*)&lt;/td&gt;
      &lt;td&gt;Y (if solution is reachable)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Optimal?&lt;/td&gt;
      &lt;td&gt;N&lt;/td&gt;
      &lt;td&gt;Y (if admissible (Tree Search) or consistent (Graph Search))&lt;/td&gt;
      &lt;td&gt;Y (same as A*)&lt;/td&gt;
      &lt;td&gt;Y (if solution is reachable)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Time&lt;/td&gt;
      &lt;td&gt;b^m&lt;/td&gt;
      &lt;td&gt;A* expands all nodes with f(n) &amp;lt; C* (C* is cost of optimal path); some nodes with f(n) = C&lt;em&gt;; no nodes with f(n) &amp;gt; C&lt;/em&gt;&lt;/td&gt;
      &lt;td&gt;hard&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Space&lt;/td&gt;
      &lt;td&gt;b^m&lt;/td&gt;
      &lt;td&gt;Exponential&lt;/td&gt;
      &lt;td&gt;b * d&lt;/td&gt;
      &lt;td&gt;constant&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;ol&gt;
  &lt;li&gt;A heuristic is admissible if it never overestimates the cost to reach the goal.&lt;/li&gt;
  &lt;li&gt;A heuristic is consistent if for every node n and every successor n’ of n generated by any action: h(n) ≤ c(n, a, n’) + h(n’). A consistent heuristic is also admissible. It is rare for an admissible heuristic to be inconsistent.&lt;/li&gt;
  &lt;li&gt;Memory-Bounded Heuristic Search:
    &lt;ul&gt;
      &lt;li&gt;Iterative-deepening A* (IDA*): Cutoff information is the f-cost (g + h) instead of depth;&lt;/li&gt;
      &lt;li&gt;Recursive best-first search (RBFS): Search depth-first, only keep current path and branches from it in memory (saves memory over keeping entire level); Keep track of f value (f-limit) of best sibling of path currently exploring; a bit more efficient than IDA*;&lt;/li&gt;
      &lt;li&gt;(Simple) Memory-bounded A* ((S)MA*): Drop the worst-leaf node when memory is full.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Branching factor → 1 ⇒ heuristic quality ↑.&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;lecture-6&quot;&gt;Lecture 6&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;The success of hill climbing depends very much on the shape of the state-space land-scape: if there are few local maxima and plateaux, random-restart hill climbing will find a good solution very quickly. NP-hard problems typically have an exponential number of local maxima to get stuck on. Despite this, a reasonably good local maximum can often be found after a small number of restarts.&lt;/li&gt;
  &lt;li&gt;Local beam search: Start with k randomly generated nodes; generate all successors of each of the k; keep the best k out of the them; repeat till goal or stop condition reached.&lt;/li&gt;
  &lt;li&gt;Simulated annealing: T ↓ ⇒ e^(△E / T) → -∞ ⇒ Probability of bad moves ↓&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;lecture-7&quot;&gt;Lecture 7&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;checkers/draughts: like chess; scrabble: like poker.&lt;/li&gt;
  &lt;li&gt;Minimax: Complete? Y; Optimal? Y; Time? O(b^m); Space? O(b * m) or O(m).&lt;/li&gt;
  &lt;li&gt;With “perfect ordering”, the alpha-beta pruning can reduce time complexity to O(b^(m/2)).&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;lecture-8&quot;&gt;Lecture 8&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;Methods for imporving backtracking efficiency in CSP:
    &lt;ul&gt;
      &lt;li&gt;Most constrained variable (minimum remaining values (MRV) heuristic): Choose the variable with the fewest legal values;&lt;/li&gt;
      &lt;li&gt;Most constraining variable: Choose the variable with the most constraints on remaining variables;&lt;/li&gt;
      &lt;li&gt;Least constraining value: Given a variable, choose the one that rules out the fewest values in the remaining variables.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Forward checking: Keep track of remaining legal values for unassigned variables; terminate search when any variable has no legal values.&lt;/li&gt;
  &lt;li&gt;Arc consistency: Simplest form of propagation makes each arc consistent: X → Y is consistent iff for every value x of X there is some allowed y. Time complexity: O(n^2 * d^3) (n variables, d values), each arc can be queued only d times, n^2 arcs (at most), checking one arc is O(d^2).&lt;/li&gt;
  &lt;li&gt;Iterative min-conflicts is often surprisingly effective in solving CSP.&lt;/li&gt;
&lt;/ol&gt;</content><author><name></name></author><category term="学习笔记" /><summary type="html">这门课程所使用的教材是 Artificial Intelligence: A Modern Approach，本份笔记直接沿用书本中对变量及名词的定义，在此没有对它们进行特殊解释。</summary></entry><entry><title type="html">《三体》书评</title><link href="/2018/08/17/%E4%B8%89%E4%BD%93-%E4%B9%A6%E8%AF%84.html" rel="alternate" type="text/html" title="《三体》书评" /><published>2018-08-17T21:00:00-07:00</published><updated>2018-08-17T21:00:00-07:00</updated><id>/2018/08/17/%E3%80%8A%E4%B8%89%E4%BD%93%E3%80%8B%E4%B9%A6%E8%AF%84</id><content type="html" xml:base="/2018/08/17/%E4%B8%89%E4%BD%93-%E4%B9%A6%E8%AF%84.html">&lt;p&gt;内容：★★★★★&lt;/p&gt;

&lt;p&gt;文笔：★★★★☆&lt;/p&gt;

&lt;p&gt;排版：★★★★★&lt;/p&gt;

&lt;p&gt;综合：★★★★★&lt;/p&gt;

&lt;p&gt;作为一名工科生，我在文学方面并没有多大的造诣，本文只简单谈谈自己一些片面的观后感，如有谬误，欢迎指正。&lt;/p&gt;

&lt;p&gt;《三体》最令我震惊的是其合理性，它不像是一本科幻小说，而是一本千万年后未来文明的历史教科书。科幻作品要做到这一点并不容易，其作者需要兼具过硬科学素质和极好的文学修养，而大刘做到了这一点。《三体》从“近代”讲起，一步一步走向深空，一步一步走向未来。在《三体 I》中人类了解到了外星文明的存在，并试图与它们建立联系，逐层揭开三体人的神秘面纱；《三体 II·黑暗森林》中罗辑与雕刻在质子上的微型计算机“智子”斗智斗勇，并悟出了“黑暗森林法则”；在《三体 III·死神永生》中人类受到了灭世的打击，太阳系被推往二维，程心与残存的人类突破光速，飞往深空，逐步认识到宇宙的终极秘密……&lt;/p&gt;

&lt;p&gt;这样一个宏大的世界观中充满了严谨的逻辑，书中不断抛出一个个困难的问题，大刘给出的解决方案让你一次次豁然开朗：面壁者们应该如何躲避智子的监控，凭一己之力对抗与自己实力悬殊的三体文明？在黑暗森林法则下三体人暗示的安全声明究竟是什么？云天明的童话中暗示的科技信息又是什么？书中给出的答案精妙无比，让你不断拍手称快。这种感受很接近你对一道数学题苦思冥想很久后，翻阅答案时的那种顿悟感。&lt;/p&gt;

&lt;p&gt;我在“文笔”这一项给出的四星并不代表大刘的文学素质不够好，相反，我这样的工科生难以望其项背。四星只是为了和《诸葛亮传》那样极致优美的文笔加以区分，《三体》中存在极少数的语言不规范并不影响它的伟大。&lt;/p&gt;

&lt;p&gt;我非常推荐所有理工科的同学们都阅读一下《三体》，它给你带来的震撼难以用言语形容，只有自己读过之后才能真切感受。&lt;/p&gt;</content><author><name></name></author><category term="阅读" /><summary type="html">内容：★★★★★</summary></entry><entry><title type="html">《大谋小计五十年：诸葛亮传 第一卷》书评</title><link href="/2018/05/24/%E5%A4%A7%E8%B0%8B%E5%B0%8F%E8%AE%A1%E4%BA%94%E5%8D%81%E5%B9%B4-%E8%AF%B8%E8%91%9B%E4%BA%AE%E4%BC%A0-%E7%AC%AC%E4%B8%80%E5%8D%B7-%E4%B9%A6%E8%AF%84.html" rel="alternate" type="text/html" title="《大谋小计五十年：诸葛亮传 第一卷》书评" /><published>2018-05-24T21:00:00-07:00</published><updated>2018-05-24T21:00:00-07:00</updated><id>/2018/05/24/%E3%80%8A%E5%A4%A7%E8%B0%8B%E5%B0%8F%E8%AE%A1%E4%BA%94%E5%8D%81%E5%B9%B4:%E8%AF%B8%E8%91%9B%E4%BA%AE%E4%BC%A0%20%E7%AC%AC%E4%B8%80%E5%8D%B7%E3%80%8B%E4%B9%A6%E8%AF%84</id><content type="html" xml:base="/2018/05/24/%E5%A4%A7%E8%B0%8B%E5%B0%8F%E8%AE%A1%E4%BA%94%E5%8D%81%E5%B9%B4-%E8%AF%B8%E8%91%9B%E4%BA%AE%E4%BC%A0-%E7%AC%AC%E4%B8%80%E5%8D%B7-%E4%B9%A6%E8%AF%84.html">&lt;p&gt;内容：★★★★☆&lt;/p&gt;

&lt;p&gt;文笔：★★★★★&lt;/p&gt;

&lt;p&gt;排版：★★★★★&lt;/p&gt;

&lt;p&gt;综合：★★★★★&lt;/p&gt;

&lt;p&gt;作为一名工科生，我在文学方面并没有多大的造诣，本文只简单谈谈自己一些片面的观后感，如有谬误，欢迎指正。&lt;/p&gt;

&lt;p&gt;正如马伯庸在本书序言中所述，作者若虚著此书的目的是洗去诸葛亮脸上的油彩。人们熟知的《三国演义》中有太多诸葛亮的浮夸故事，因此若虚希望能还原出一个“有血有肉、真情实感”的诸葛亮。作者确实做到了这一点，若虚在研读大量史实之后在此基础上进行猜想，细节丰富地描述了诸葛亮从几岁到二十几岁这一时间阶段的生活经历，如果将历史文献中的诸葛亮比作像素图，那么这本书中的诸葛亮就如 AR 立体模型一般真实。&lt;/p&gt;

&lt;p&gt;作者对文字的驾驭能力堪称一流。书中诸葛亮和刘备这两条主线同时推进，起初它们像两条平行线，但渐渐地它们有了夹角，似乎会在不久的将来相会。作者善以景衬情，对自然事物的描写信手拈来，让读者眼中有画，也能真切体会到人物情感。作者还会时不时摘来一两句引用，或是赋一两首诗歌，让读者嗅到书香。最令我惊叹的是书中对诸葛亮几次辩述的描写，诸葛亮通过言语辩倒对手时，作者也需辩倒读者，诸葛亮有理有据地证明着自己论点时，也是体现着本书作者对这些问题的深刻思考。&lt;/p&gt;

&lt;p&gt;在我看来，卷一美中不足的是作者并没能“抹去诸葛亮脸上的油彩”。可能因为作者本身对诸葛亮的痴情，全书字里行间内都透着他/她对诸葛亮的喜爱。除在他年幼习棋时，本书中的诸葛亮对弈未尝败过一场。这里的对弈不只指围棋，还指围棋的各种变体，以及民间大众喜欢的各种博弈游戏；诸葛亮的对手也不只指路人甲乙丙丁，还包括世间各路顶级高手。但凡是智力比拼，诸葛亮也未尝败过一场，唯一的遗憾是在队友拖后腿的情况下与庞统战平，除此之外的比拼诸葛亮均全胜。若虚去除了“草船借箭”、“空城计”这样的神话，但他/她却杜撰出了另一批神话。&lt;/p&gt;

&lt;p&gt;《大谋小计五十年：诸葛亮传》全书分为五卷，我所借阅的是第一卷。本卷内容是人们较少知晓的诸葛亮幼年时期的故事，如果大家有兴趣的话，不妨一读。&lt;/p&gt;</content><author><name></name></author><category term="阅读" /><summary type="html">内容：★★★★☆</summary></entry><entry><title type="html">《天才在左 疯子在右》书评</title><link href="/2018/05/24/%E5%A4%A9%E6%89%8D%E5%9C%A8%E5%B7%A6-%E7%96%AF%E5%AD%90%E5%9C%A8%E5%8F%B3-%E4%B9%A6%E8%AF%84.html" rel="alternate" type="text/html" title="《天才在左 疯子在右》书评" /><published>2018-05-24T21:00:00-07:00</published><updated>2018-05-24T21:00:00-07:00</updated><id>/2018/05/24/%E3%80%8A%E5%A4%A9%E6%89%8D%E5%9C%A8%E5%B7%A6%20%E7%96%AF%E5%AD%90%E5%9C%A8%E5%8F%B3%E3%80%8B%E4%B9%A6%E8%AF%84</id><content type="html" xml:base="/2018/05/24/%E5%A4%A9%E6%89%8D%E5%9C%A8%E5%B7%A6-%E7%96%AF%E5%AD%90%E5%9C%A8%E5%8F%B3-%E4%B9%A6%E8%AF%84.html">&lt;p&gt;内容：★★★★☆&lt;/p&gt;

&lt;p&gt;文笔：★★★☆☆&lt;/p&gt;

&lt;p&gt;排版：★★☆☆☆&lt;/p&gt;

&lt;p&gt;综合：★★★☆☆&lt;/p&gt;

&lt;p&gt;作为一名工科生，我在文学方面并没有多大的造诣，本文只简单谈谈自己一些片面的观后感，如有谬误，欢迎指正。&lt;/p&gt;

&lt;p&gt;这本书最吸引人的当属它的内容，作者高铭耗时数年与数百位精神病人进行深入交谈，期间通过录音和笔记详细地记录了他与病人间的交流过程，最后经过整理，完成了这一本书。&lt;/p&gt;

&lt;p&gt;值得注意的是，这本书并不是一份客观的访谈手记。照作者的原话，正文 48 个篇章中仅“近20余篇”来自真实案例，且这些案例也经过“增添或删减”。也许是为了达到某些艺术效果，作者“神化”了不少精神病人。比如书中多次提到有病人使用尖端的量子物理知识来构造自己的世界观，我很怀疑作者在著书时查阅了不少相关资料，替那些病人圆他们的观点，让那些病人的理论显得天衣无缝。这样一来，书的可读性和趣味性都会上升，但书也会因丢失了真实性而成为小说。当然，书中的一些思考是深刻的，作者写书的目的不在于将其作为医学案例供后人分析，而是希望读者能看到更宽广的世界。&lt;/p&gt;

&lt;p&gt;本书包含大段对白，遣词造句十分口语化，对交谈双方的神情、动作和心理没有过多的描写，不过也不奇怪，本书是事发后一年由作者按录音和笔记进行整理，缺乏细节在所难免。另外作者本身并不严谨，书中出现了类似“按百分比来说，某某大概占三分之一”这样的措辞，作者对《黑客帝国》这一部电影的英语称呼在书中也前后不一。&lt;/p&gt;

&lt;p&gt;我从中山大学图书馆中借到了这本书，它由 2015 届某毕业生捐赠，因此可能为盗版书籍。书中有数量可观的错别字，印刷质量也不高。&lt;/p&gt;

&lt;p&gt;总的来说，这是一本有意思的书。&lt;/p&gt;</content><author><name></name></author><category term="阅读" /><summary type="html">内容：★★★★☆</summary></entry><entry><title type="html">香港澳门之旅</title><link href="/2018/05/12/%E9%A6%99%E6%B8%AF%E6%BE%B3%E9%97%A8%E4%B9%8B%E6%97%85.html" rel="alternate" type="text/html" title="香港澳门之旅" /><published>2018-05-12T21:00:00-07:00</published><updated>2018-05-12T21:00:00-07:00</updated><id>/2018/05/12/%E9%A6%99%E6%B8%AF%E6%BE%B3%E9%97%A8%E4%B9%8B%E6%97%85</id><content type="html" xml:base="/2018/05/12/%E9%A6%99%E6%B8%AF%E6%BE%B3%E9%97%A8%E4%B9%8B%E6%97%85.html">&lt;p&gt;最近和 shuq3 去了一趟香港和澳门，这些是我们在途中拍摄的照片。&lt;/p&gt;

&lt;div id=&quot;photo-container&quot;&gt;&lt;/div&gt;

&lt;div id=&quot;hint&quot;&gt;正在加载...加载完成大约需要 20M 的流量。&lt;/div&gt;

&lt;script&gt;
  times = 0;
  interval = setInterval(function() {
    times += 1;
    if (times === 87) {
      clearInterval(interval);
      $('#hint').html('加载完成！');
    }
    $('#photo-container').append('&lt;img class=&quot;photo&quot; src=&quot;https://raw.githubusercontent.com/An0nym6/Images/master/blog%20images/Trip%20to%20HK%20%26%20MO/' + times + '.jpg&quot;/&gt;');
  }, 2000);
&lt;/script&gt;</content><author><name></name></author><category term="旅行" /><summary type="html">最近和 shuq3 去了一趟香港和澳门，这些是我们在途中拍摄的照片。</summary></entry><entry><title type="html">如何在不同网络环境下调试网站</title><link href="/2018/03/11/%E5%A6%82%E4%BD%95%E5%9C%A8%E4%B8%8D%E5%90%8C%E7%BD%91%E7%BB%9C%E7%8E%AF%E5%A2%83%E4%B8%8B%E8%B0%83%E8%AF%95%E7%BD%91%E7%AB%99.html" rel="alternate" type="text/html" title="如何在不同网络环境下调试网站" /><published>2018-03-11T21:00:00-07:00</published><updated>2018-03-11T21:00:00-07:00</updated><id>/2018/03/11/%E5%A6%82%E4%BD%95%E5%9C%A8%E4%B8%8D%E5%90%8C%E7%BD%91%E7%BB%9C%E7%8E%AF%E5%A2%83%E4%B8%8B%E8%B0%83%E8%AF%95%E7%BD%91%E7%AB%99</id><content type="html" xml:base="/2018/03/11/%E5%A6%82%E4%BD%95%E5%9C%A8%E4%B8%8D%E5%90%8C%E7%BD%91%E7%BB%9C%E7%8E%AF%E5%A2%83%E4%B8%8B%E8%B0%83%E8%AF%95%E7%BD%91%E7%AB%99.html">&lt;p&gt;很多人都知道 Chrome 开发者工具的 Network 下可以自定义网络环境，Chrome 可以模拟在 Fast 3G、Slow 3G 等一系列网络环境中加载页面：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/An0nym6/Images/master/blog%20images/Fiddler%20%26%20Clumsy/1.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如果你只是想简单地调试调试本地网站，那么这个工具可以满足你的需求。但是使用这种方法只能“放慢”网络，如果你本身的网络环境就很糟糕，加载网站的时间很长，或者你需要更加高级的网络设置，比如设置丢包率，压低带宽值，那么这个工具并不能满足你的需求。这篇文章希望解决的问题是将网络环境可控化，基本的设想是，将外部网站缓存在不受网络环境干扰的内网，然后人工地制造时延、丢包、带宽限制等因素。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/An0nym6/Images/master/blog%20images/Fiddler%20%26%20Clumsy/2.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;代理服务器&quot;&gt;代理服务器&lt;/h4&gt;

&lt;p&gt;在代理服务器上我们需要用到 Web 调试工具 Fiddler。它本身的功能有很多，在这里我们需要用到的是它的监听功能和 AutoResponder。Fiddler 可以监听当前机器上发出的 HTTP 请求及收到的 HTTP 响应，并可以按照进程 ID 对捕获到的数据进行过滤。AutoResponder 可以使用捕获到的数据模拟 Web 服务器对客户端作出响应。&lt;/p&gt;

&lt;p&gt;首先，我们需要使用代理服务器上的浏览器访问我们需要调试的网站，在此期间使用 Fiddler 捕获所有进出的 HTTP 数据包，将它们缓存在本地。然后，我们打开 AutoResponder，它将使用先前缓存的 HTTP 响应回复发往本机 8888 端口的 HTTP 请求。最后，我们还需要设置 Clumsy 来制造我们所需的网络环境。&lt;/p&gt;

&lt;p&gt;下图为 AutoResponder 代理 http://www.qq.com：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/An0nym6/Images/master/blog%20images/Fiddler%20%26%20Clumsy/3.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;下图为使用 Clumsy 在 8888 端口上制造我们所需的网络环境：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/An0nym6/Images/master/blog%20images/Fiddler%20%26%20Clumsy/4.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;访问方&quot;&gt;访问方&lt;/h4&gt;

&lt;p&gt;我们只需要设置浏览器代理，让它将所有 HTTP 请求都发往 代理服务器IP:8888 即可，比如 Chrome 浏览器可以使用插件 SwitchyOmega。至此，我们需要调试的网站所处网络环境就是完全可控的了。&lt;/p&gt;</content><author><name></name></author><category term="网络" /><summary type="html">很多人都知道 Chrome 开发者工具的 Network 下可以自定义网络环境，Chrome 可以模拟在 Fast 3G、Slow 3G 等一系列网络环境中加载页面：</summary></entry></feed>